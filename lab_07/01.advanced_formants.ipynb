{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Emphasis",
   "id": "ad271f8302e43ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "6e1b28660565adc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter\n",
    "from scipy.signal.windows import hamming\n",
    "from scipy.linalg import solve_toeplitz"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Formant Detection Using LPC\n",
    "\n",
    "##### **Step 1. Load and Prepare the Audio Signal**\n",
    "The audio file is loaded using the `wavfile.read()` function from the scipy.io module, capturing both the sample rate and the audio signal data. To ensure the audio is suitable for processing, the code checks if the audio is stereo (more than one channel). If it is, the two channels are averaged to create a mono audio signal. After that, the audio signal is normalized to fit within the range of `[-1, 1]` by dividing it by its maximum absolute value, ensuring consistent amplitude levels across different signals.\n",
    "\n",
    "##### **Step 2. Compute the Spectrogram**\n",
    "A spectrogram is generated to visualize the frequency content of the audio signal over time. It represents how the signal's frequency content varies over time, providing insights into the characteristics of the speech signal.\n",
    "\n",
    "##### **Step 3. Formant Detection Using LPC**\n",
    "The code performs LPC analysis to detect formants in the audio signal. The audio is processed in frames, where each frame has a length of 25 milliseconds (`frame_length`) and advances by 10 milliseconds (`frame_step`). A Hamming window is applied to each frame to minimize spectral leakage during analysis.\n",
    "\n",
    "The autocorrelation of the frame is computed, and the LPC coefficients are derived by solving a Toeplitz system. The roots of the LPC polynomial are calculated, focusing only on roots with positive imaginary parts. These roots are then converted to frequencies, representing the formants. The detected formants' frequencies and their corresponding time indices are stored in `formants_time` and `formants_freqs` lists for later visualization.\n",
    "\n",
    "##### **Step 4. Overlay Formants on the Spectrogram**\n",
    "The detected formants are overlaid on the previously computed spectrogram for visual comparison. Each formant's frequency is plotted against its corresponding time point, allowing for an analysis of how well the formants align with the spectral features in the audio signal.\n",
    "\n",
    "#### **Tips**:\n",
    "- Test with both speech signals!"
   ],
   "id": "33becbd5a2ebba75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the speech sample\n",
    "path_folder = \"audio_samples_07/\"\n",
    "file_name = 'FILE_NAME'   # Replace with your file path\n",
    "file_ext = '.wav'\n",
    "\n",
    "filename = path_folder + file_name + file_ext\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Step 2: Check if audio is stereo and convert to mono if necessary\n",
    "if audio.ndim > 1:  # Check if audio has more than one channel\n",
    "    audio = audio.mean(axis=1)  # Average the two channels to create mono audio\n",
    "\n",
    "# Step 3: Normalize the audio\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "# Step 4: Compute the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.specgram(audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title('Spectrogram of Speech Sample')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "# Step 5: Formant detection using LPC\n",
    "frame_length = int(0.025 * sampling_rate)  # 25ms frame\n",
    "frame_step = int(0.010 * sampling_rate)    # 10ms step\n",
    "\n",
    "num_formants = 3\n",
    "formants_time = []\n",
    "formants_freqs = []\n",
    "\n",
    "for i in range(0, len(audio) - frame_length, frame_step):\n",
    "    frame = audio[i:i + frame_length]\n",
    "    frame = frame * hamming(frame_length)  # Apply Hamming window\n",
    "    \n",
    "    # LPC analysis\n",
    "    order = 2 + sampling_rate // 1000  # Typical LPC order\n",
    "    autocorr = np.correlate(frame, frame, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "    \n",
    "    R = autocorr[:order + 1]\n",
    "    r = R[1:]\n",
    "    a = solve_toeplitz((R[:order], R[:order]), r)\n",
    "    \n",
    "    # Compute the roots of the LPC polynomial\n",
    "    roots = np.roots(np.concatenate(([1], -a)))\n",
    "    roots = roots[np.imag(roots) >= 0]  # Consider only roots with positive imaginary parts\n",
    "    \n",
    "    angles = np.angle(roots)\n",
    "    formant_freqs = sorted(angles * (sampling_rate / (2 * np.pi)))\n",
    "    formant_freqs = formant_freqs[:num_formants]  # Take the first 'num_formants' frequencies\n",
    "    \n",
    "    formants_time.append(i / sampling_rate)\n",
    "    formants_freqs.append(formant_freqs)\n",
    "\n",
    "# Step 6: Overlay formants on the spectrogram\n",
    "formants_freqs = np.array(formants_freqs)\n",
    "for i in range(num_formants):\n",
    "    plt.plot(formants_time, formants_freqs[:, i], label=f'Formant {i+1}', linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "199963474809dedf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Formant Shifting\n",
    "\n",
    "##### **Step 1. Load Audio Signal**\n",
    "The audio file is loaded using `wavfile.read()`, capturing the sample rate and the signal data. To ensure uniform amplitude levels across signals, the audio data is normalized to fit within a range of `[âˆ’1, 1]`. This is done by dividing the signal values by the maximum absolute value in the signal.\n",
    "\n",
    "##### **Step 2. Check Audio Format and Normalize**\n",
    "To handle audio files properly, the code checks if the audio signal is stereo. If the audio has two channels, it averages them to create a mono audio signal. Following this, the audio is normalized to fit the range of `[-1, 1]`, ensuring that all audio signals can be processed without distortion.\n",
    "\n",
    "##### **Step 3. Set Parameters for LPC Analysis**\n",
    "Parameters for the Linear Predictive Coding (LPC) analysis are defined, including the frame length and step size. In this case, the frame length is set to `25 ms`, and the frame step is set to `10 ms`. Additionally, the LPC order is calculated based on the sample rate, which is a typical value for LPC analysis.\n",
    "\n",
    "##### **Step 4. Apply LPC to Analyze the Audio**\n",
    "The code processes the audio in overlapping frames. For each frame, the Hamming window is applied to smooth the edges of the frame before analysis. The autocorrelation of the frame is computed to derive the LPC coefficients, which represent the vocal tract's resonances.\n",
    "\n",
    "##### **Step 5. Formant Frequency Calculation and Spectrogram Display**\n",
    "The roots of the LPC polynomial are computed to identify formant frequencies. These frequencies are extracted, and their time points are recorded. The spectrogram of the audio is plotted using `plt.specgram()`, which provides a visual representation of the audio's frequency content over time. The identified formant frequencies are then overlaid on the spectrogram for visual comparison.\n",
    "\n",
    "##### **Step 6. Shift Formants Using LPC Coefficients**\n",
    "A new section of the code modifies the LPC coefficients to shift the formant frequencies. The `shift_ratio` determines the amount of shift applied to the formants. For each frame, the new LPC coefficients are calculated by multiplying the original coefficients by the shift ratio raised to the power of their respective indices. This process approximates the desired shift in formant frequencies.\n",
    "\n",
    "##### **Step 7. Reconstruct the Audio Signal**\n",
    "Using the modified LPC coefficients, the audio signal is reconstructed for each frame. The filtered signal is created by applying the `lfilter` function, which processes the audio based on the new LPC coefficients. The reconstructed frames are combined to form the complete shifted audio signal.\n",
    "\n",
    "##### **Step 8. Save the Reconstructed Audio to a New WAV File**\n",
    "\n",
    "#### **Tips**:\n",
    "- Test with both speech signals!"
   ],
   "id": "400aec39c889b9f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the speech sample\n",
    "path_folder = \"audio_samples_07/\"\n",
    "file_name = 'FILE_NAME'   # Replace with your file path\n",
    "file_ext = '.wav'\n",
    "\n",
    "filename = path_folder + file_name + file_ext\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Step 2: Check if audio is stereo and convert to mono if necessary and normalize it\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)\n",
    "\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "# Step 3: Formant detection using LPC\n",
    "frame_length = int(0.025 * sampling_rate)\n",
    "frame_step = int(0.010 * sampling_rate)\n",
    "\n",
    "num_formants = 3\n",
    "formants_time = []\n",
    "formants_freqs = []\n",
    "\n",
    "# Initialize a reconstructed signal\n",
    "reconstructed_audio = np.zeros(len(audio))\n",
    "\n",
    "for i in range(0, len(audio) - frame_length, frame_step):\n",
    "    frame = audio[i:i + frame_length]\n",
    "    frame = frame * hamming(frame_length)  # Apply Hamming window\n",
    "    \n",
    "    order = 2 + sampling_rate // 1000\n",
    "    autocorr = np.correlate(frame, frame, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "    \n",
    "    R = autocorr[:order + 1]\n",
    "    r = R[1:]\n",
    "    a = solve_toeplitz((R[:order], R[:order]), r)\n",
    "    \n",
    "    roots = np.roots(np.concatenate(([1], -a)))\n",
    "    roots = roots[np.imag(roots) >= 0]\n",
    "    \n",
    "    angles = np.angle(roots)\n",
    "    formant_freqs = sorted(angles * (sampling_rate / (2 * np.pi)))\n",
    "    formant_freqs = formant_freqs[:num_formants]\n",
    "    \n",
    "    formants_time.append(i / sampling_rate)\n",
    "    formants_freqs.append(formant_freqs)\n",
    "\n",
    "# Step 4: Shift the formants\n",
    "shift_ratio = 1.1  # Shift formants upward by 10%\n",
    "shifted_freqs = np.array(formants_freqs) * shift_ratio\n",
    "\n",
    "# Step 5: Adjust LPC coefficients based on shifted formants\n",
    "# Create a new LPC coefficient array with the same order\n",
    "shifted_a = np.zeros(order + 1)\n",
    "shifted_a[0] = 1.0  # The first coefficient is always 1.0 for stability\n",
    "\n",
    "# Calculate new LPC coefficients based on shifting\n",
    "for j in range(1, min(order + 1, len(a))):  # Limit to the size of `a`\n",
    "    shifted_a[j] = a[j] * (shift_ratio ** j)  # Simple approximation for demonstration\n",
    "\n",
    "# Step 6: Reconstruct the audio signal using the modified LPC coefficients\n",
    "for i in range(0, len(audio) - frame_length, frame_step):\n",
    "    frame = audio[i:i + frame_length]\n",
    "    frame = frame * hamming(frame_length)  # Apply Hamming window\n",
    "\n",
    "    # Reconstruct the audio signal using the modified LPC coefficients\n",
    "    reconstructed_frame = lfilter(shifted_a, [1], frame)\n",
    "    reconstructed_audio[i:i + len(reconstructed_frame)] += reconstructed_frame\n",
    "\n",
    "# Step 7: Compute and plot spectrograms\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Original Spectrogram\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.specgram(audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title('Original Spectrogram')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "# Shifted Spectrogram\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.specgram(reconstructed_audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title('Shifted Spectrogram')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 8: Save the reconstructed audio to a new WAV file\n",
    "output_file_name = f'{file_name}_formant_shifted.wav'   # Specify your output file path\n",
    "reconstructed_audio = reconstructed_audio / np.max(np.abs(reconstructed_audio))  # Normalize if needed\n",
    "wav.write(output_file_name, sampling_rate, (reconstructed_audio * 32767).astype(np.int16))  # Save as 16-bit PCM"
   ],
   "id": "b6d9b137f7e2e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Formant Boosting\n",
    "\n",
    "##### **Step 1. Load Audio Signal**\n",
    "The audio file containing the speech sample is loaded using `wav.read()`, retrieving both the sample rate and the audio signal data. The filename is specified, pointing to the .wav file to be analyzed.\n",
    "\n",
    "##### **Step 2. Check if Audio is Stereo and Convert to Mono**\n",
    "Check if the audio signal is stereo (more than one channel). If it is, the two channels are averaged to create a mono audio signal, which simplifies further analysis.\n",
    "\n",
    "##### **Step 3. Normalize the Audio**\n",
    "The audio signal is normalized by dividing it by its maximum absolute value. This step ensures that the audio values are scaled to a range of `[-1, 1]`, preventing clipping during processing.\n",
    "\n",
    "##### **Step 4. Formant Detection Using LPC**\n",
    "Parameters are set for analyzing the audio signal in frames. A frame length of `25 ms` and a step size of `10 ms` are defined. Arrays are initialized to store the time and frequency data of the detected formants. A loop iterates through the audio signal, applying a Hamming window to each frame and performing Linear Predictive Coding (LPC) analysis to calculate the LPC coefficients. The roots of the LPC polynomial are computed to determine the formant frequencies, which are then stored for later visualization.\n",
    "\n",
    "##### **Step 5. Overlay Formants on the Spectrogram (Original)**\n",
    "A spectrogram of the original audio signal is generated using `plt.specgram()`, displaying frequency content over time. The detected formants are plotted on top of the spectrogram to visualize their positions in the frequency domain.\n",
    "\n",
    "##### **Step 6. Boost Formants**\n",
    "The LPC coefficients are boosted by a specified factor to enhance the formant amplitudes. Each frame is processed similarly to the original audio, and the boosted coefficients are used to reconstruct the audio signal. The resulting audio signal is accumulated into a single reconstructed audio array.\n",
    "\n",
    "##### **Step 7. Save the Boosted Audio to a New WAV File**\n",
    "The reconstructed audio is normalized again to ensure it fits within the appropriate range before saving it to a new WAV file.\n",
    "\n",
    "##### **Step 8. Plot the Spectrogram of the Boosted Audio**\n",
    "A new spectrogram is generated for the boosted audio.\n",
    "\n",
    "#### **Tips**:\n",
    "- Test with both speech signals!"
   ],
   "id": "8e44645e4d9528fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the speech sample\n",
    "path_folder = \"audio_samples_07/\"\n",
    "file_name = 'FILE_NAME'   # Replace with your file path\n",
    "file_ext = '.wav'\n",
    "\n",
    "filename = path_folder + file_name + file_ext\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Step 2: Check if audio is stereo and convert to mono if necessary\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)  # Average the two channels to create mono audio\n",
    "\n",
    "# Step 3: Normalize the audio\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "# Step 4: Formant detection using LPC\n",
    "frame_length = int(0.025 * sampling_rate)  # 25ms frame\n",
    "frame_step = int(0.010 * sampling_rate)    # 10ms step\n",
    "\n",
    "num_formants = 3\n",
    "formants_time = []\n",
    "formants_freqs = []\n",
    "\n",
    "# Initialize a reconstructed signal\n",
    "reconstructed_audio = np.zeros(len(audio))\n",
    "\n",
    "# Formant detection loop\n",
    "for i in range(0, len(audio) - frame_length, frame_step):\n",
    "    frame = audio[i:i + frame_length]\n",
    "    frame = frame * hamming(frame_length)  # Apply Hamming window\n",
    "    \n",
    "    order = 2 + sampling_rate // 1000  # Typical LPC order\n",
    "    autocorr = np.correlate(frame, frame, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "    \n",
    "    R = autocorr[:order + 1]\n",
    "    r = R[1:]\n",
    "    a = solve_toeplitz((R[:order], R[:order]), r)\n",
    "    \n",
    "    # Formant frequency calculation\n",
    "    roots = np.roots(np.concatenate(([1], -a)))\n",
    "    roots = roots[np.imag(roots) >= 0]  # Consider only roots with positive imaginary parts\n",
    "    \n",
    "    angles = np.angle(roots)\n",
    "    formant_freqs = sorted(angles * (sampling_rate / (2 * np.pi)))\n",
    "    formant_freqs = formant_freqs[:num_formants]  # Take the first 'num_formants' frequencies\n",
    "    \n",
    "    formants_time.append(i / sampling_rate)\n",
    "    formants_freqs.append(formant_freqs)\n",
    "\n",
    "# Step 5: Overlay formants on the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.specgram(audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "formants_freqs = np.array(formants_freqs)\n",
    "for i in range(num_formants):\n",
    "    plt.plot(formants_time, formants_freqs[:, i], label=f'Formant {i+1}', linewidth=2)\n",
    "\n",
    "plt.title('Spectrogram of Speech Sample with Formants (Original)')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Boost Formants\n",
    "boost_factor = 2.0  # Example boost factor to increase formant amplitudes\n",
    "reconstructed_audio = np.zeros(len(audio))\n",
    "\n",
    "for i in range(0, len(audio) - frame_length, frame_step):\n",
    "    frame = audio[i:i + frame_length]\n",
    "    boosted_frame = frame * hamming(frame_length)\n",
    "    \n",
    "    # Apply LPC analysis\n",
    "    order = 2 + sampling_rate // 1000  # Typical LPC order\n",
    "    autocorr = np.correlate(boosted_frame, boosted_frame, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "\n",
    "    R = autocorr[:order + 1]\n",
    "    r = R[1:]\n",
    "    a = solve_toeplitz((R[:order], R[:order]), r)\n",
    "    \n",
    "    # Ensure the size of boosted_a matches the order of LPC coefficients\n",
    "    boosted_a = np.zeros(len(a))  # Initialize boosted_a based on the length of a\n",
    "    boosted_a[0] = 1.0\n",
    "    for j in range(1, len(a)):  # Use len(a) to ensure we do not go out of bounds\n",
    "        boosted_a[j] = a[j] * boost_factor  # Boost the coefficients\n",
    "    \n",
    "    # Reconstruct the audio signal using the modified LPC coefficients\n",
    "    reconstructed_frame = lfilter(boosted_a, [1], boosted_frame)\n",
    "    reconstructed_audio[i:i + frame_length] += reconstructed_frame\n",
    "\n",
    "# Step 7: Save the boosted audio to a new WAV file\n",
    "output_filename = 'audio_samples_07/speech_formant_boosted.wav'  # Specify your output file path\n",
    "reconstructed_audio = reconstructed_audio / np.max(np.abs(reconstructed_audio))  # Normalize if needed\n",
    "wav.write(output_filename, sampling_rate, (reconstructed_audio * 32767).astype(np.int16))  # Save as 16-bit PCM\n",
    "\n",
    "# Step 8: Plot the spectrogram of the boosted audio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.specgram(reconstructed_audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "\n",
    "# Overlay the formants on the boosted spectrogram\n",
    "formants_time_boosted = []\n",
    "formants_freqs_boosted = []\n",
    "\n",
    "for i in range(0, len(reconstructed_audio) - frame_length, frame_step):\n",
    "    frame = reconstructed_audio[i:i + frame_length]\n",
    "    frame = frame * hamming(frame_length)\n",
    "    \n",
    "    order = 2 + sampling_rate // 1000\n",
    "    autocorr = np.correlate(frame, frame, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]\n",
    "\n",
    "    R = autocorr[:order + 1]\n",
    "    r = R[1:]\n",
    "    a = solve_toeplitz((R[:order], R[:order]), r)\n",
    "    \n",
    "    # Formant frequency calculation\n",
    "    roots = np.roots(np.concatenate(([1], -a)))\n",
    "    roots = roots[np.imag(roots) >= 0]\n",
    "    \n",
    "    angles = np.angle(roots)\n",
    "    formant_freqs = sorted(angles * (sampling_rate / (2 * np.pi)))\n",
    "    formant_freqs = formant_freqs[:num_formants]\n",
    "    \n",
    "    formants_time_boosted.append(i / sampling_rate)\n",
    "    formants_freqs_boosted.append(formant_freqs)\n",
    "\n",
    "# Overlay formants on the boosted spectrogram\n",
    "formants_freqs_boosted = np.array(formants_freqs_boosted)\n",
    "for i in range(num_formants):\n",
    "    plt.plot(formants_time_boosted, formants_freqs_boosted[:, i], label=f'Boosted Formant {i+1}', linewidth=2)\n",
    "\n",
    "plt.title('Spectrogram of Boosted Speech Sample with Formants')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "255e46aa5aca7247",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
