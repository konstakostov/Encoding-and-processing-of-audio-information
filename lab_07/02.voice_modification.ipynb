{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pitch Shifting",
   "id": "ad271f8302e43ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "6e1b28660565adc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft, istft"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Pitch Shifting using TD-PSOLA (Time-Domain Pitch-Synchronous Overlap and Add)\n",
    "\n",
    "##### **Step 1. Load and Preprocess Audio**\n",
    "- `Loading Audio:` The audio file is loaded using `scipy.io.wavfile.read()`, and the audio is converted to mono if it's stereo.\n",
    "- `Normalization:` The audio is normalized to ensure it lies within the range `[-1, 1]`.\n",
    "\n",
    "##### **Step 2. Set Pitch Shifting Parameters and Frame Processing**\n",
    "- `Pitch Factor:` The pitch factor is set to `x`, meaning the pitch will be raised by a factor of `x`. Set `pitch_factor` values to `2`, `4` and `8`.\n",
    "- `Frame Size and Hop Size:` The audio is split into overlapping frames with a `frame_size` of `512` samples and `hop_size` of `128` to ensure overlap.\n",
    "- `Frame Extraction:` We extract the frames from the audio using a list comprehension.\n",
    "\n",
    "##### **Step 3. Pitch Shifting Using Frame Resampling**\n",
    "- `Frame Resampling:` For each frame, the size is adjusted according to the pitch factor. A larger pitch factor results in a smaller frame size, raising the pitch.\n",
    "- `Interpolation:` The frame is resampled using `np.interp()`, which performs linear interpolation to match the new frame size.\n",
    "\n",
    "##### **Step 4. Post-Processing**\n",
    "- `Clipping:` The resulting audio is clipped to ensure it stays within the valid range for audio playback `([-1, 1])`.\n",
    "- `Saving:` The pitch-shifted audio is saved to a new .wav file after scaling it to the 16-bit integer range.\n",
    "\n",
    "##### **Step 5. Visualizing Audio**\n",
    "- `Spectrograms:` The original and pitch-shifted audio are visualized as spectrograms. This helps to confirm the pitch shift by showing the change in frequency content over time.\n",
    "\n",
    "#### **Tips**:\n",
    "- Set the proper file name!\n",
    "- Set `pitch_factor`, `frame_size` and `hop_size` as defined in Step 2."
   ],
   "id": "33becbd5a2ebba75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the audio file\n",
    "filename = 'audio_samples_07/FILE_NAME.wav'  # Replace with your .wav file\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Ensure audio is mono\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)\n",
    "\n",
    "# Normalize audio\n",
    "audio = audio / np.max(np.abs(audio))  # Normalize audio\n",
    "\n",
    "# TD-PSOLA pitch shifting\n",
    "pitch_factor = ?\n",
    "frame_size = ?\n",
    "hop_size = ?\n",
    "\n",
    "# Divide audio into frames\n",
    "frames = []\n",
    "for i in range(0, len(audio) - frame_size, hop_size):\n",
    "    frames.append(audio[i:i + frame_size])\n",
    "\n",
    "# Apply time-synchronous overlap-add to modify pitch\n",
    "new_audio = []\n",
    "for i, frame in enumerate(frames):\n",
    "    # Shift pitch by changing frame length based on pitch factor\n",
    "    new_frame_size = int(frame_size / pitch_factor)  # Adjust frame size to preserve original duration\n",
    "    new_frame = np.interp(np.linspace(0, frame_size, new_frame_size), np.arange(frame_size), frame)\n",
    "    new_audio.extend(new_frame)\n",
    "\n",
    "new_audio = np.array(new_audio)\n",
    "\n",
    "# Ensure the audio is within range [-1, 1]\n",
    "new_audio = np.clip(new_audio, -1, 1)\n",
    "\n",
    "# Save the pitch-shifted audio\n",
    "output_filename = 'td_psola_pitch_shifted.wav'\n",
    "wav.write(output_filename, sampling_rate, (new_audio * 32767).astype(np.int16))\n",
    "\n",
    "# Plot the original and pitch-shifted audio\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Original spectrogram\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.specgram(audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title('Original Audio')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "# Shifted spectrogram\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.specgram(new_audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title(f'Pitch-Shifted Audio (TD-PSOLA, Factor: {pitch_factor})')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "199963474809dedf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Pitch Shifting Using Phase Vocode\n",
    "\n",
    "##### **Step 1. Load and preprocess the audio**\n",
    "Load the audio file using `scipy.io.wavfile.read()`, which returns the sampling rate and the audio data. If the audio is stereo (more than one channel), it is converted to mono by averaging the channels using `audio.mean(axis=1)`. The audio is then normalized by dividing by the maximum absolute value to ensure the audio signal stays within the range of `-1` to `1`.\n",
    "\n",
    "##### **Step 2. Define pitch-shifting parameters**\n",
    "Set up the parameters for the pitch shifting process. The `pitch_factor` is specified, where a value greater than 1 increases the pitch, and a value less than 1 decreases it. The `window_size` defines the size of the frames for the STFT, and the `hop_size` determines the overlap between consecutive frames.\n",
    "\n",
    "##### **Step 3. Compute the Short-Time Fourier Transform (STFT)**\n",
    "The STFT is applied to the audio using the `scipy.signal.stft()` function, which splits the audio signal into overlapping frames and transforms each frame into the frequency domain. The result, `Zxx`, contains complex numbers representing both the magnitude and phase of each frequency component at each time frame.\n",
    "\n",
    "##### **Step 4. Pitch shifting via frequency bin interpolation**\n",
    "The number of frequency bins is adjusted based on the pitch_factor. If the pitch is to be increased, the number of frequency bins will be greater than the original number, and if the pitch is to be decreased, the number of frequency bins will be reduced. This is done by interpolating the magnitude of the frequency bins across the new bin count using `np.interp()`. The phase information, obtained using `np.angle()`, is kept unchanged during the interpolation process.\n",
    "\n",
    "##### **Step 5. Reconstruct the time-domain signal using inverse STFT**\n",
    "After modifying the frequency bins, the inverse STFT is performed using `scipy.signal.istft()`, which reconstructs the audio signal from the shifted frequency bins back into the time domain.\n",
    "\n",
    "##### **Step 6. Normalize and save the modified audio**\n",
    "The pitch-shifted audio is then normalized to the range of -1 to 1 and saved to a new WAV file using `scipy.io.wavfile.write()`.\n",
    "\n",
    "##### **Step 7. Visualize the results**\n",
    "The original and pitch-shifted audio are visualized by plotting their spectrograms using `matplotlib.pyplot.specgram()`. \n",
    "#### **Tips**:\n",
    "- Set the proper file name!\n",
    "- Set `pitch_factor`, `frame_size` and `hop_size` as defined in Step 2 in the previous code cell."
   ],
   "id": "400aec39c889b9f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the audio file\n",
    "filename = 'audio_samples_07/FILE_NAME.wav'  # Replace with your .wav file\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Ensure audio is mono\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)\n",
    "\n",
    "# Normalize the audio\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "# Set parameters for pitch shifting using Phase Vocoder\n",
    "pitch_factor = ?  # Greater than 1 raises pitch, less than 1 lowers it\n",
    "window_size = ?  # Size of the window for STFT\n",
    "hop_size = ?\n",
    "\n",
    "# Perform STFT (Short-Time Fourier Transform)\n",
    "frequencies, times, Zxx = stft(audio, fs=sampling_rate, nperseg=window_size, noverlap=hop_size)\n",
    "\n",
    "# Phase Vocoder Pitch Shifting\n",
    "num_bins, num_frames = Zxx.shape\n",
    "new_num_bins = int(num_bins * pitch_factor)\n",
    "\n",
    "# Initialize a new array for shifted frequencies\n",
    "shifted_Zxx = np.zeros((new_num_bins, num_frames), dtype=complex)\n",
    "\n",
    "# Interpolate to shift pitch\n",
    "for i in range(num_frames):\n",
    "    # Interpolate magnitude\n",
    "    magnitude = np.abs(Zxx[:, i])\n",
    "    interpolated_magnitude = np.interp(\n",
    "        np.linspace(0, num_bins, new_num_bins), np.arange(num_bins), magnitude\n",
    "    )\n",
    "    \n",
    "    # Interpolate phase\n",
    "    phase = np.angle(Zxx[:, i])\n",
    "    interpolated_phase = np.interp(\n",
    "        np.linspace(0, num_bins, new_num_bins), np.arange(num_bins), phase\n",
    "    )\n",
    "\n",
    "    # Reconstruct the shifted frequency bins\n",
    "    shifted_Zxx[:, i] = interpolated_magnitude * np.exp(1j * interpolated_phase)\n",
    "\n",
    "# Perform inverse STFT to reconstruct the audio signal\n",
    "_, shifted_audio = istft(shifted_Zxx, fs=sampling_rate, nperseg=window_size, noverlap=hop_size)\n",
    "\n",
    "# Normalize the audio to ensure it remains within range [-1, 1]\n",
    "shifted_audio = shifted_audio / np.max(np.abs(shifted_audio))\n",
    "\n",
    "# Save the pitch-shifted audio\n",
    "output_filename = 'phase_vocoder_pitch_shifted.wav'\n",
    "wav.write(output_filename, sampling_rate, (shifted_audio * 32767).astype(np.int16))\n",
    "\n",
    "# Plot the original and pitch-shifted audio spectrograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the original audio spectrogram\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.specgram(audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title('Original Audio')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "# Plot the pitch-shifted audio spectrogram\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.specgram(shifted_audio, Fs=sampling_rate, NFFT=2048, noverlap=1024, cmap='plasma')\n",
    "plt.title(f'Pitch-Shifted Audio (Phase Vocoder, Factor: {pitch_factor})')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "b6d9b137f7e2e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Pitch Shifting Using Autocorrelation and Harmonic/Percussive Separation\n",
    "\n",
    "##### **Step 1. Load the Audio File:**\n",
    "The audio file is read into the `audio` array, and it's converted to mono if it's stereo.\n",
    "\n",
    "##### **Step 2. Autocorrelation**\n",
    "The autocorrelation is computed by using np.correlate() for the signal. We then extract the second half of the result, which corresponds to positive time lags. The peak index in this correlation is used to calculate the pitch period, and the pitch frequency is determined from this period.\n",
    "\n",
    "##### **Step 3. Harmonic/Percussive Separation**\n",
    "For simplicity, we simulate harmonic content by scaling the audio by a factor of `0.8` and assume the rest is percussive.\n",
    "\n",
    "##### **Step 4. Pitch Shifting**\n",
    "The harmonic content is stretched (or compressed) by resampling it using `np.interp()`, based on the pitch factor (`1.5` in this case).\n",
    "\n",
    "##### **Step 5. Combining the Modified Harmonic and Percussive Content*\n",
    "The harmonic part is resampled, and the percussive content is added back (adjusted to match the length of the resampled harmonic).\n",
    "\n",
    "##### **Step 6. Clipping**\n",
    "The resulting audio is clipped to ensure it remains in the valid range `[-1, 1]`.\n",
    "\n",
    "##### **Step 7. Saving the Audio**\n",
    "The processed audio is saved to a new `.wav` file.\n",
    "\n",
    "##### **Step 8. Plotting**\n",
    "The original and the pitch-shifted audio waveforms are plotted for comparison.\n",
    "\n",
    "\n",
    "#### **Tips**:\n",
    "- Set the proper file name!\n",
    "- Set `harmonic` and `pitch_factor`as defined in Step 3 & 4 in the previous code cell."
   ],
   "id": "8e44645e4d9528fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the audio file\n",
    "filename = 'audio_samples_07/FILE_NAME.wav'  # Replace with your .wav file\n",
    "sampling_rate, audio = wav.read(filename)\n",
    "\n",
    "# Ensure audio is mono\n",
    "if audio.ndim > 1:\n",
    "    audio = audio.mean(axis=1)\n",
    "\n",
    "# Normalize audio\n",
    "audio = audio / np.max(np.abs(audio))  # Normalize audio to range [-1, 1]\n",
    "\n",
    "# Step 2: Apply Autocorrelation for pitch detection\n",
    "# Calculate autocorrelation of the signal manually\n",
    "result = np.correlate(audio, audio, mode='full')\n",
    "corr = result[result.size // 2:]  # Take the second half of the result, which contains the positive lags\n",
    "\n",
    "# Find the peak index, which corresponds to the pitch period\n",
    "peak_index = np.argmax(corr)  # Index of the maximum correlation\n",
    "pitch_period = peak_index  # This corresponds to the pitch period\n",
    "\n",
    "# Ensure pitch_period is not zero to avoid divide by zero error\n",
    "if pitch_period != 0:\n",
    "    pitch_frequency = sampling_rate / pitch_period  # Frequency = sample rate / period\n",
    "else:\n",
    "    pitch_frequency = 0  # Handle case where pitch_period is zero\n",
    "\n",
    "# Step 3: Harmonic/Percussive Separation (simplified approach)\n",
    "# Simulate harmonic content (only part of the signal we modify)\n",
    "harmonic = audio * ?  # Assume 80% of the signal is harmonic\n",
    "percussive = audio - harmonic  # Percussive content is just the remainder\n",
    "\n",
    "# Step 4: Modify harmonic content for pitch shifting\n",
    "pitch_factor = ?  # Increase pitch by a factor of 1.5\n",
    "num_samples = len(harmonic)\n",
    "new_num_samples = int(num_samples / pitch_factor)\n",
    "\n",
    "# Stretch the harmonic content by resampling (simple approach)\n",
    "harmonic_resampled = np.interp(np.linspace(0, num_samples, new_num_samples), np.arange(num_samples), harmonic)\n",
    "\n",
    "# Step 5: Combine modified harmonic and percussive content\n",
    "output_audio = harmonic_resampled + percussive[:len(harmonic_resampled)]  # Combine with percussive content\n",
    "\n",
    "# Step 6: Ensure the output is within the range [-1, 1]\n",
    "output_audio = np.clip(output_audio, -1, 1)\n",
    "\n",
    "# Step 7: Save the pitch-shifted audio\n",
    "output_filename = 'autocorrelation_pitch_shifted_audio.wav'\n",
    "wav.write(output_filename, sampling_rate, (output_audio * 32767).astype(np.int16))\n",
    "\n",
    "# Step 8: Plot the original and pitch-shifted audio signals\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Original audio\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.linspace(0, len(audio) / sampling_rate, len(audio)), audio)\n",
    "plt.title('Original Audio')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Pitch-shifted audio\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.linspace(0, len(output_audio) / sampling_rate, len(output_audio)), output_audio)\n",
    "plt.title(f'Pitch-Shifted Audio (Autocorrelation, Factor: {pitch_factor})')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "255e46aa5aca7247",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
