{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Perceptual optimization",
   "id": "ad271f8302e43ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "6e1b28660565adc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Visualize Masking Effects\n",
    "\n",
    "##### **Step 1. Load the Audio File*\n",
    "Load a provided stereo or mono audio file in `.wav` format. Ensure that the file is in a supported format and contains clear audio for visualization purposes.\n",
    "\n",
    "##### **Step 2. Compute the Spectrogram of the Audio Signal*\n",
    "The spectrogram provides a visual way to analyze how the signal’s frequency content changes over time, allowing for a clearer view of both high and low energy regions in the audio.\n",
    "\n",
    "##### **Step 3. Define and Apply a Masking Threshold**\n",
    "- A simple masking threshold is defined using a constant multiplier (`masking_constant`) and applied directly to the spectrogram’s power data to simulate masking effects.\n",
    "- By applying `np.sqrt(spectrogram_data)` scaled by `masking_constant`, a masking threshold is generated that approximates where high-energy frequencies can mask quieter, nearby frequencies.\n",
    "- This threshold can be adjusted with different constants to demonstrate varying levels of masking effect strength.\n",
    "\n",
    "##### **Step 4. Plot the Spectrogram with the Masking Threshold Overlay*\n",
    "The spectrogram provides a visual way to analyze how the signal’s frequency content changes over time, allowing for a clearer view of both high and low energy regions in the audio.\n"
   ],
   "id": "33becbd5a2ebba75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Use appropriate file path\n",
    "\n",
    "if signal.ndim > 1:\n",
    "    signal = signal.mean(axis=1)  # Convert to mono if the file is stereo\n",
    "\n",
    "# Step 2: Compute the spectrogram of the audio signal\n",
    "frequencies, times, spectrogram_data = spectrogram(signal, sample_rate)\n",
    "\n",
    "# Step 3: Define and apply a masking threshold\n",
    "masking_constant = 1.0  # Basic constant for threshold demonstration\n",
    "masking_thresholds = masking_constant * np.sqrt(spectrogram_data)\n",
    "\n",
    "# Step 4: Plot the spectrogram and the calculated masking threshold\n",
    "eps = 1e-10  # Small offset to prevent log10(0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram_data + eps), shading='gouraud', cmap='viridis')\n",
    "plt.colorbar(label=\"Power/Frequency (dB/Hz)\")\n",
    "plt.plot(times, masking_thresholds.mean(axis=0), color='red', label=\"Masking Threshold (Average)\")\n",
    "plt.ylim(0, sample_rate / 2)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.title(\"Spectrogram with Masking Threshold Overlay\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "199963474809dedf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Apply Basic Perceptual Filtering\n",
    "\n",
    "##### **Step 1. Load the Audio Signal**\n",
    "The audio file is loaded. If it's stereo, it is converted to mono by averaging the channels.\n",
    "\n",
    "##### **Step 2. Define the Perceptual Filter and Apply the Filter**\n",
    "A basic perceptual filter is defined. The threshold parameter determines the level below which the signal is considered negligible. If the absolute value of the signal is below this threshold, it is set to zero.\n",
    "\n",
    "##### **Step 3. Plot Results**\n",
    "The original and filtered signals are plotted for visual comparison. The original signal is displayed in blue, and the filtered signal in red."
   ],
   "id": "400aec39c889b9f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Use appropriate file path\n",
    "\n",
    "if signal.ndim > 1:\n",
    "    signal = signal.mean(axis=1)  # Convert to mono if the file is stereo\n",
    "\n",
    "# Step 2: Define a basic perceptual filter\n",
    "threshold = ???  # Threshold parameter for filtering\n",
    "filtered_signal = np.where(np.abs(signal) < threshold, 0, signal)  # Zero out values below the threshold\n",
    "\n",
    "# Ensure the filtered signal has no NaN values\n",
    "filtered_signal = np.nan_to_num(filtered_signal)\n",
    "\n",
    "# Step 3: Compare the original and filtered signals\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original signal\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(signal, color='blue', alpha=0.6, label='Original Signal')\n",
    "plt.title(\"Original Audio Signal\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Filtered signal\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(filtered_signal, color='red', alpha=0.6, label='Filtered Signal')\n",
    "plt.title(\"Filtered Audio Signal\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Save the filtered signal as .wav\n",
    "# Ensure that the filtered signal is within the proper range\n",
    "filtered_signal = np.clip(filtered_signal, -1, 1)  # Clip values to ensure they are within the range\n",
    "wavfile.write('filtered_signal.wav', sample_rate, (filtered_signal * 32767).astype(np.int16))"
   ],
   "id": "b6d9b137f7e2e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Compare Results of Basic Perceptual Filtering\n",
    "\n",
    "##### **Step 1. Load the Audio File**\n",
    "The audio file is loaded, and if it's stereo, it is converted to mono by averaging the channels.\n",
    "\n",
    "##### **Step 2. Define Thresholds**\n",
    "A list of different threshold values is created to demonstrate the effect of perceptual filtering.\n",
    "\n",
    "##### **Step 3. Apply Filtering**\n",
    "For each threshold, the code applies the perceptual filter. Values below the threshold are zeroed out, and the filtered signals are stored in a list.\n",
    "\n",
    "##### **Step 4. Visualization**\n",
    "The original audio signal is plotted first, followed by the filtered signals for each threshold. This helps in comparing how different thresholds affect the audio signal."
   ],
   "id": "8e44645e4d9528fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Use appropriate file path\n",
    "\n",
    "if signal.ndim > 1:\n",
    "    signal = signal.mean(axis=1)  # Convert to mono if the file is stereo\n",
    "\n",
    "# Step 2: Define a range of threshold values\n",
    "thresholds = [?, ?, ?]  # Different threshold values for comparison\n",
    "filtered_signals = []  # List to store filtered signals for each threshold\n",
    "\n",
    "# Step 3: Apply perceptual filtering for each threshold and store results\n",
    "for threshold in thresholds:\n",
    "    filtered_signal = np.where(np.abs(signal) < threshold, 0, signal)  # Zero out values below the threshold\n",
    "    filtered_signals.append(filtered_signal)\n",
    "\n",
    "# Step 4: Visualize the original and filtered signals for each threshold\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Plot original signal\n",
    "plt.subplot(len(thresholds) + 1, 1, 1)\n",
    "plt.plot(signal, color='blue', alpha=0.6, label='Original Signal')\n",
    "plt.title(\"Original Audio Signal\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot filtered signals for each threshold\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    plt.subplot(len(thresholds) + 1, 1, i + 2)\n",
    "    plt.plot(filtered_signals[i], color='red', alpha=0.6, label=f'Filtered Signal (Threshold: {threshold})')\n",
    "    plt.title(f\"Filtered Audio Signal (Threshold: {threshold})\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "255e46aa5aca7247",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
