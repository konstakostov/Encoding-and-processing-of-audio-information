{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Emphasis",
   "id": "ad271f8302e43ccb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "6e1b28660565adc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import Audio"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Apply Pre-emphasis with Different Coefficients\n",
    "\n",
    "##### **Step 1. Load Audio Signal**\n",
    "\n",
    "##### **Step 2. Normalize the Audio Signal**\n",
    "To ensure uniform amplitude levels across signals, the audio data is normalized to fit within a range of \n",
    "`[−1, 1]`. This is done by dividing the signal values by the maximum absolute value in the signal.\n",
    "\n",
    "##### **Step 3. Apply Pre-emphasis Filter**\n",
    "The pre-emphasis filter is applied to the signal for each specified coefficient value `(0.95, 0.97, 0.99)`. This is done by iterating over each sample and subtracting a portion of the previous sample from the current sample. Higher coefficients apply stronger filtering to enhance higher frequencies. The filtered signals are stored in a list for later comparison.\n",
    "\n",
    "##### **Step 4. Apply Pre-emphasis Filter**\n",
    "Using the Fast Fourier Transform (FFT), the frequency spectra of the original and pre-emphasized signals are calculated.\n",
    "\n",
    "#### Tips:\n",
    "- Use the specified coefficients in Step 2."
   ],
   "id": "33becbd5a2ebba75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Replace with your file path\n",
    "\n",
    "# Check if the signal is stereo and convert to mono if needed\n",
    "if len(signal.shape) > 1:\n",
    "    signal = signal[:, 0]  # Take only one channel if it's a stereo file\n",
    "\n",
    "# Normalize the audio signal\n",
    "signal = signal / np.max(np.abs(signal))  # Normalize to range [-1, 1]\n",
    "\n",
    "# Define pre-emphasis coefficients to be applied\n",
    "coefficients = [?, ?, ?]\n",
    "\n",
    "# Initialize a dictionary to hold the pre-emphasized signals\n",
    "pre_emphasized_signals = []\n",
    "\n",
    "# Step 2: Apply pre-emphasis with different coefficients\n",
    "for alpha in coefficients:\n",
    "    emphasized_signal = np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "    pre_emphasized_signals.append(emphasized_signal)\n",
    "\n",
    "# Step 3: Visualize the spectra\n",
    "plt.figure(figsize=(12, 8))\n",
    "freqs = np.fft.rfftfreq(len(signal), d=1/sample_rate)\n",
    "\n",
    "# Plot original spectrum\n",
    "original_spectrum = np.abs(np.fft.rfft(signal))\n",
    "plt.plot(freqs, original_spectrum, label=\"Original Signal\", color='blue', linewidth=1)\n",
    "\n",
    "# Plot pre-emphasized spectra for each coefficient\n",
    "colors = ['red', 'green', 'orange']\n",
    "for i, alpha in enumerate(coefficients):\n",
    "    emphasized_spectrum = np.abs(np.fft.rfft(pre_emphasized_signals[i]))\n",
    "    plt.plot(freqs, emphasized_spectrum, label=f'Pre-emphasis (α={alpha})', color=colors[i], linewidth=1)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Spectra of Original and Pre-emphasized Signals\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "199963474809dedf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Compare Audio Quality with Different Pre-emphasis Settings\n",
    "\n",
    "##### **Step 1. Load Audio Signal**\n",
    "The audio file is loaded using `wavfile.read()`, capturing the sample rate and the signal data. To ensure uniform amplitude levels across signals, the audio data is normalized to fit within a range of `[−1, 1]`. This is done by dividing the signal values by the maximum absolute value in the signal.\n",
    "\n",
    "##### **Step 2. Apply Pre-emphasis with Different Coefficients**\n",
    "The pre-emphasis filter is applied to the signal for each specified coefficient value `(0.95, 0.97, 0.99)`. This is done by iterating over each sample and subtracting a portion of the previous sample from the current sample. Higher coefficients apply stronger filtering to enhance higher frequencies. The filtered signals are stored in a list for later comparison.\n",
    "\n",
    "##### **Step 3. Plot Waveforms Before and After Pre-emphasis**\n",
    "To observe the effect of pre-emphasis, the original and filtered signals are plotted in the time domain.\n",
    "\n",
    "##### **Step 4. Listen to Processed Audio**\n",
    "Using the Fast Fourier Transform (FFT), the frequency spectra of the original and pre-emphasized signals are calculated.\n",
    "\n",
    "#### Tips:\n",
    "- Use the specified coefficients in Step 2.\n",
    "- To play all processed files use the indices `0`, `1` and `2` separately for each playback. Also use the defined sampling rate, **not** one of your choosing."
   ],
   "id": "400aec39c889b9f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Replace with your file path\n",
    "\n",
    "# Check if the signal is stereo and convert to mono if needed\n",
    "if len(signal.shape) > 1:\n",
    "    signal = signal[:, 0]  # Take only one channel if it's a stereo file\n",
    "\n",
    "# Normalize audio signal\n",
    "signal = signal / np.max(np.abs(signal))  # Normalize to the range [-1, 1]\n",
    "\n",
    "# Define pre-emphasis coefficients\n",
    "coefficients = [?, ?, ?]\n",
    "\n",
    "# Initialize list to hold processed signals for each coefficient\n",
    "processed_signals = []\n",
    "\n",
    "# Apply pre-emphasis with each coefficient\n",
    "for alpha in coefficients:\n",
    "    emphasized_signal = np.copy(signal)\n",
    "    emphasized_signal[1:] = signal[1:] - alpha * signal[:-1]\n",
    "    processed_signals.append(emphasized_signal)\n",
    "\n",
    "# Plot original and processed signals\n",
    "time_axis = np.linspace(0, len(signal) / sample_rate, num=len(signal))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot original signal\n",
    "plt.subplot(len(coefficients) + 1, 1, 1)\n",
    "plt.plot(time_axis, signal, color='blue')\n",
    "plt.title(\"Original Signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot each processed signal\n",
    "for i, alpha in enumerate(coefficients):\n",
    "    plt.subplot(len(coefficients) + 1, 1, i + 2)\n",
    "    plt.plot(time_axis, processed_signals[i], color='green')\n",
    "    plt.title(f\"Pre-emphasized Signal (Coefficient = {alpha})\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Playback of processed audio\n",
    "Audio(processed_signals[?], rate=???)"
   ],
   "id": "b6d9b137f7e2e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Audio Equalization and Frequency Response Visualization\n",
    "\n",
    "##### **Step 1. Load Audio File**\n",
    "The audio file is loaded using `wavfile.read()`, capturing the sample rate and the signal data. The signal is normalized by dividing it by its maximum absolute value. This rescales the signal to a range of [-1, 1], which is essential for effective audio processing and prevents clipping during filtering.\n",
    "\n",
    "##### **Step 2.  Define the Butterworth Bandpass Filter**\n",
    "A Butterworth bandpass filter is defined using the `butter` function from the `scipy.signal` module:\n",
    "- Parameters: The function takes the low and high cutoff frequencies (`lowcut` and `highcut`), the sampling frequency (`fs`), and the filter order.\n",
    "- The Nyquist frequency is calculated, and the normalized frequencies for the filter are determined.\n",
    "- The filter coefficients are computed and returned for use in filtering the audio signal.\n",
    "\n",
    "##### **Step 3. Apply the Bandpass Filter for Equalization*\n",
    "An equalization effect is applied to the audio signal:\n",
    "\n",
    "- The low and high cutoff frequencies are set to `300` Hz and `3400` Hz, respectively. This configuration boosts frequencies around 300 Hz while cutting those above 3400 Hz, which is often beneficial for enhancing speech intelligibility.\n",
    "- The `apply_bandpass_filter` function uses the filter coefficients to process the signal, resulting in the `equalized_signal`.\n",
    "\n",
    "##### **Step 4. Plot the Magnitude Spectrum**\n",
    "The code defines a function to plot the magnitude spectrum of the audio signals (original and processed):\n",
    "- The function uses `plt.psd()` to compute the Power Spectral Density (PSD) and then applies a logarithmic scale for better visualization. A small constant is added to prevent taking the logarithm of zero.\n",
    "\n",
    "##### **Step 5. Play the Equalized Audio Signal**\n",
    "\n",
    "#### Tips:\n",
    "- Apply the cutoff frequencies, specified in Step 3.\n",
    "- To play the audio file use the defined sampling rate, **not** one of your choosing."
   ],
   "id": "8e44645e4d9528fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the audio file\n",
    "sample_rate, signal = wavfile.read('audio_samples_06/FILE_NAME.wav')  # Replace with your file path\n",
    "\n",
    "# Check if the signal is stereo and convert to mono if needed\n",
    "if len(signal.shape) > 1:\n",
    "    signal = signal[:, 0]  # Take only one channel if it's a stereo file\n",
    "\n",
    "# Normalize audio signal\n",
    "signal = signal / np.max(np.abs(signal))  # Normalize to the range [-1, 1]\n",
    "\n",
    "# Define Butterworth bandpass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return lfilter(b, a, signal)\n",
    "\n",
    "# Apply equalization\n",
    "# Boost frequencies around 300 Hz and cut frequencies above 3400 Hz\n",
    "lowcut = ?\n",
    "highcut = ?\n",
    "equalized_signal = apply_bandpass_filter(signal, lowcut, highcut, sample_rate)\n",
    "\n",
    "# Function to plot magnitude spectrum\n",
    "def plot_magnitude_spectrum(signal, fs, label, color):\n",
    "    # Compute the frequency spectrum\n",
    "    f, Pxx = plt.psd(signal, NFFT=2048, Fs=fs, noverlap=1024, color=color, label=label)\n",
    "    # Prevent divide by zero in log10\n",
    "    Pxx = np.maximum(Pxx, 1e-10)  # Avoid log(0) by setting a minimum value\n",
    "    plt.plot(f, 10 * np.log10(Pxx), label=label, color=color)  # Use 10 * log10 for power spectrum\n",
    "\n",
    "# Plot original signal frequency response\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_magnitude_spectrum(signal, sample_rate, 'Original Signal', 'blue')\n",
    "plt.title(\"Original Signal Frequency Response\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude (dB)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Plot equalized signal frequency response\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_magnitude_spectrum(equalized_signal, sample_rate, 'Equalized Signal', 'red')\n",
    "plt.title(\"Equalized Signal Frequency Response\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude (dB)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Play equalized audio signal\n",
    "Audio(equalized_signal, rate=?)\n"
   ],
   "id": "255e46aa5aca7247",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
