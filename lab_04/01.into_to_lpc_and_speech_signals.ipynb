{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Въведение в линейното предсказване и речевите сигнали",
   "id": "c1db57495f4048a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "69163eeec96eb92b"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.linalg import toeplitz\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Load and Visualize a Speech Signal\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "Load the .wav file using scipy.io.wavfile.read(). If the signal is stereo, it's converted to mono by averaging the channels. <br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Analyze Signal Properties**\n",
    "Calculate the duration of the audio signal and print out key properties such as the sampling rate and the total number of samples. This information provides insights into the characteristics of the audio.\n",
    "\n",
    "##### **Step 3. Plot the Waveform**\n",
    "Create a time array corresponding to the signal samples to visualize amplitude variations over time. The waveform visually represents the audio characteristics.\n",
    "\n",
    "##### **Step 4. Playback**\n",
    "Playback the speech signal directly within the Jupyter notebook using the `IPython.display.Audio` class, allowing for listening to the speech without needing external players."
   ],
   "id": "7189f6089e22436b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the speech signal\n",
    "file_path = 'speech_samples/speech_test_01.wav'  # Ensure the path is correct\n",
    "sampling_rate, signal = wavfile.read(file_path)\n",
    "\n",
    "# Convert stereo to mono if necessary\n",
    "if len(signal.shape) > 1:\n",
    "    signal = np.mean(signal, axis=1)\n",
    "\n",
    "# Analyze signal properties\n",
    "duration = len(signal) / sampling_rate\n",
    "print(f'Sampling Rate: {sampling_rate} Hz')\n",
    "print(f'Total Samples: {len(signal)}')\n",
    "print(f'Duration: {duration:.2f} seconds')\n",
    "\n",
    "# Plot the waveform\n",
    "time = np.linspace(0, duration, len(signal))\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time, signal)\n",
    "plt.title('Speech Signal Waveform')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Playback the signal\n",
    "Audio(data=signal, rate=sampling_rate)"
   ],
   "id": "860040baac4fd19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Compare LPC and FFT Spectra\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "Load the .wav file using scipy.io.wavfile.read(). If the signal is stereo, it's converted to mono by averaging the channels. <br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Select a Frame**\n",
    "Select a small frame of 256 samples from the speech signal for analysis. This frame represents a short segment of the audio to focus on.\n",
    "\n",
    "##### **Step 3. FFT Spectrum Calculation**\n",
    "Compute the FFT of the selected frame using `np.fft.fft()`. Calculate the magnitude of the FFT and extract the first 256 frequency bins, which correspond to the positive half of the spectrum.\n",
    "\n",
    "##### **Step 4. LPC Spectrum Calculation**\n",
    "Using the autocorrelation method, compute the LPC coefficients. Solve a linear system to derive these coefficients. Calculate the frequency response of the LPC model over the same frequency range as the FFT and compute the magnitude.\n",
    "\n",
    "##### **Step 5. Plot**\n",
    "Plot both the FFT and LPC spectra on the same graph for visual comparison, allowing for an easy assessment of the differences and similarities between the two methods.\n",
    "\n",
    "##### **Step 6. Playback**\n",
    "Playback the selected speech signal segment directly within the Jupyter notebook using the `IPython.display.Audio` class."
   ],
   "id": "772a0b897bb651b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the speech signal\n",
    "file_path = 'speech_samples/speech_test_02.wav'  # Ensure the path is correct\n",
    "sampling_rate, signal = wavfile.read(file_path)\n",
    "\n",
    "# Convert stereo to mono if necessary\n",
    "if len(signal.shape) > 1:\n",
    "    signal = np.mean(signal, axis=1)\n",
    "\n",
    "# Select a frame for analysis\n",
    "frame_start = 1000  # Starting index for the frame\n",
    "frame_size = 256    # Number of samples in the frame\n",
    "frame = signal[frame_start:frame_start + frame_size]\n",
    "\n",
    "# FFT Spectrum Calculation\n",
    "fft_spectrum = np.fft.fft(frame, n=frame_size)\n",
    "fft_magnitude = np.abs(fft_spectrum)[:frame_size // 2]  # Positive half of the spectrum\n",
    "frequencies = np.fft.fftfreq(frame_size, d=1/sampling_rate)[:frame_size // 2]\n",
    "\n",
    "# LPC Spectrum Calculation\n",
    "# Auto-correlation\n",
    "r = np.correlate(frame, frame, mode='full')\n",
    "r = r[len(r)//2:len(r)//2 + 12 + 1]  # Get the first order + 1 lags\n",
    "\n",
    "# Solve for LPC coefficients using Levinson-Durbin recursion\n",
    "a = np.linalg.solve(toeplitz(r[:-1]), -r[1:])\n",
    "\n",
    "# Calculate LPC frequency response\n",
    "w = np.linspace(0, np.pi, 1024)\n",
    "H_lpc = np.zeros_like(w, dtype=complex)\n",
    "for i, omega in enumerate(w):\n",
    "    H_lpc[i] = 1 / (1 + sum(a[k] * np.exp(-1j * k * omega) for k in range(1, len(a))))\n",
    "\n",
    "# Plot both spectra\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot FFT Spectrum\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(frequencies, 20 * np.log10(fft_magnitude), label='FFT Spectrum')\n",
    "plt.title('FFT Spectrum')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Plot LPC Spectrum\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.linspace(0, sampling_rate / 2, len(H_lpc)), 20 * np.log10(np.abs(H_lpc)), label='LPC Spectrum', color='orange')\n",
    "plt.title('LPC Spectrum')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Playback the selected frame\n",
    "Audio(data=frame, rate=sampling_rate)"
   ],
   "id": "1b7325860d81b07b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Formant Extraction Using LPC Coefficients\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "We load the .wav file using scipy.io.wavfile.read(). If the signal is stereo, it's converted to mono by averaging the channels.<br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Select a Frame for Analysis**\n",
    "A specific frame of 256 samples is extracted from the speech signal, starting at index 1000. This frame will be analyzed for LPC coefficients.\n",
    "\n",
    "##### **Step 3. Compute LPC Coefficients**\n",
    "The autocorrelation function of the selected frame is computed. LPC coefficients are derived by solving a linear system using Levinson-Durbin recursion, which processes the autocorrelation values.\n",
    "\n",
    "##### **Step 4. Calculate Roots of the LPC Polynomial**\n",
    "The roots of the LPC polynomial are computed using the `np.roots()` function, which represents the resonant frequencies or formants of the vocal tract.\n",
    "\n",
    "##### **Step 5. Calculate Frequencies and Damping**\n",
    "The frequencies of the formants are determined by calculating the angle of the roots and converting it to Hertz. The damping factors are derived from the absolute values of the roots.\n",
    "\n",
    "##### **Step 6. Filter Non-Positive Frequencies**\n",
    "Any non-positive formant frequencies are filtered out to ensure that only valid frequencies are retained for analysis.\n",
    "\n",
    "##### **Step 7. Plot Formants in the Complex Plane**\n",
    "The valid formant frequencies are visualized in the complex plane using a scatter plot. The real and imaginary parts of the roots are plotted to show their distribution.\n",
    "\n",
    "##### **Step 8. Playbacks**\n",
    "The selected frame of the speech signal is played back in the Jupyter Notebook for auditory confirmation."
   ],
   "id": "5445f879b05dc685"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the speech signal\n",
    "file_path = 'speech_samples/speech_test_02.wav'  # Ensure the path is correct\n",
    "sampling_rate, signal = wavfile.read(file_path)\n",
    "\n",
    "# Convert stereo to mono if necessary\n",
    "if len(signal.shape) > 1:\n",
    "    signal = np.mean(signal, axis=1)\n",
    "\n",
    "# Select a frame for analysis\n",
    "frame_start = 1000  # Starting index for the frame\n",
    "frame_size = 256    # Number of samples in the frame\n",
    "frame = signal[frame_start:frame_start + frame_size]\n",
    "\n",
    "# Compute LPC coefficients\n",
    "# Auto-correlation\n",
    "r = np.correlate(frame, frame, mode='full')\n",
    "r = r[len(r)//2:len(r)//2 + 12 + 1]  # Get the first order + 1 lags\n",
    "\n",
    "# Solve for LPC coefficients using Levinson-Durbin recursion\n",
    "a = np.linalg.solve(toeplitz(r[:-1]), -r[1:])\n",
    "\n",
    "# Compute the LPC polynomial roots\n",
    "roots = np.roots(np.hstack(([1], a)))\n",
    "\n",
    "# Calculate the frequencies and damping of the formants\n",
    "frequencies = np.angle(roots) * (sampling_rate / (2 * np.pi))  # Formant frequencies in Hz\n",
    "dampings = np.abs(roots)  # Damping factors\n",
    "\n",
    "# Filter out the non-positive frequencies\n",
    "valid_indices = frequencies > 0\n",
    "formant_frequencies = frequencies[valid_indices]\n",
    "formant_dampings = dampings[valid_indices]\n",
    "formant_roots = roots[valid_indices]\n",
    "\n",
    "# Display formant frequencies\n",
    "print(\"Formant Frequencies (Hz):\", formant_frequencies)\n",
    "\n",
    "# Plot formants in the complex plane\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(np.real(formant_roots), np.imag(formant_roots), marker='o', color='red')\n",
    "plt.title('Formant Frequencies in Complex Plane')\n",
    "plt.xlabel('Real Part')\n",
    "plt.ylabel('Imaginary Part')\n",
    "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "plt.xlim(-1, 1)  # Adjust limits for better visualization\n",
    "plt.ylim(-1, 1)  # Adjust limits for better visualization\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Playback the selected frame\n",
    "Audio(data=frame, rate=sampling_rate)\n"
   ],
   "id": "969246e4f0d9849e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
