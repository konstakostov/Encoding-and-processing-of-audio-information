{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Оценяване на резонансните честоти (форманти) от речеви сигнали",
   "id": "ddb0ddb60c049d65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import required libraries",
   "id": "fd2a8480250384c9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Extracting Formants from a Speech Signal\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "Load the .wav file using scipy.io.wavfile.read(). If the signal is stereo, it's converted to mono by averaging the channels. <br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Define Frame Parameters*\n",
    "Define the parameters for processing the audio signal, including the `frame_length` (2048 samples) and `hop_length` (512 samples). These parameters dictate how the audio is segmented for analysis.\n",
    "\n",
    "##### **Step 3. Extract Formants**\n",
    "For each frame of the audio signal, perform the following:\n",
    "- Compute the Fast Fourier Transform (FFT) to analyze the frequency spectrum of the frame.\n",
    "- Identify the indices of the three highest peaks in the frequency spectrum, which correspond to the first three formant frequencies (F1, F2, F3).\n",
    "\n",
    "##### **Step 4. Store Results**\n",
    "Store the extracted formant frequencies along with their corresponding time (in milliseconds) in a list. After processing all frames, convert this list into a Pandas DataFrame for easier handling and analysis.\n",
    "##### **Step 5. Extract Formants**\n",
    "The roots of the polynomial are analyzed to determine the formants. Only the roots with positive imaginary parts are considered, as they represent the formants in the complex plane.\n",
    "\n",
    "##### **Step 6. Plot Formants**\n",
    "Visualize the extracted formants over time using `matplotlib`. Create line plots for each of the first three formants (F1, F2, F3) against time, allowing for a clear view of how these frequencies change throughout the speech signal."
   ],
   "id": "2e332d0fad2388a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load audio file\n",
    "file_path = 'speech_samples/speech_test_01.wav'  # Replace with your .wav file path\n",
    "sr, y = wavfile.read(file_path)\n",
    "\n",
    "# If stereo, take only one channel\n",
    "if len(y.shape) > 1:\n",
    "    y = y[:, 0]\n",
    "\n",
    "# Frame parameters\n",
    "frame_length = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# Initialize a list to store formants\n",
    "formants = []\n",
    "\n",
    "# Extract formants\n",
    "for i in range(0, len(y), hop_length):\n",
    "    if i + frame_length <= len(y):\n",
    "        frame = y[i:i + frame_length]\n",
    "        # Perform FFT on the frame\n",
    "        spectrum = np.abs(np.fft.rfft(frame))\n",
    "        freqs = np.fft.rfftfreq(len(frame), 1/sr)\n",
    "        \n",
    "        # Identify peaks in the spectrum to estimate formants\n",
    "        peaks = np.argsort(spectrum)[-3:]  # Get indices of top 3 frequencies\n",
    "        formants.append([i / sr * 1000, freqs[peaks[0]], freqs[peaks[1]], freqs[peaks[2]]])\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "formants_df = pd.DataFrame(formants, columns=['Time (ms)', 'F1', 'F2', 'F3'])\n",
    "\n",
    "# Visualization of formants using matplotlib\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(formants_df['Time (ms)'], formants_df['F1'], label='F1', color='blue', linewidth=2)\n",
    "plt.plot(formants_df['Time (ms)'], formants_df['F2'], label='F2', color='green', linewidth=2)\n",
    "plt.plot(formants_df['Time (ms)'], formants_df['F3'], label='F3', color='red', linewidth=2)\n",
    "\n",
    "plt.title('Formants Over Time')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "793d6d17c741a15b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Comparing Formant Frequencies of Vowel Sounds\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "Load the .mp3 file containing multiple vowels using librosa.load(). This function reads the audio file and returns two outputs: the audio time series (as a NumPy array) and the sample rate. <br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Define Frame Parameters**\n",
    "Define the parameters for processing the audio signal, including the `frame_length` (2048 samples) and `hop_length` (512 samples). These parameters dictate how the audio is segmented for analysis.\n",
    "\n",
    "##### **Step 3. Initialize Storage for Formants**\n",
    "Create a dictionary to store the extracted formants for each vowel. Also, define a list of vowel labels `('a', 'e', 'i', 'o', 'u')` that will be used to identify the formants.\n",
    "\n",
    "##### **Step 4. Specify Vowel Intervals**\n",
    "Specify the time intervals for each vowel within the audio file. These intervals define the sections of the audio that correspond to the individual vowels, given in seconds.\n",
    "\n",
    "##### **Step 5.  Extract Formants for Each Vowel**\n",
    "For each vowel interval, extract the formants:\n",
    "1. Select the segment of audio corresponding to the vowel.\n",
    "2. Process the segment in overlapping frames:\n",
    "    - Compute the Fast Fourier Transform (FFT) of each frame to analyze its frequency spectrum.\n",
    "    - Identify the indices of the three highest peaks in the frequency spectrum, corresponding to the first three formant frequencies (F1, F2, F3).\n",
    "3. Store the time (in milliseconds) and the identified formants in a list, which is then converted to a Pandas DataFrame.\n",
    "\n",
    "##### **Step 6. Plot Formants for Each Formnat**\n",
    "For each vowel, plot the formant frequencies (F1, F2, F3) over time."
   ],
   "id": "444ba04e0188caff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the .mp3 file containing multiple vowels\n",
    "file_path = 'speech_samples/vowels.mp3'  # Replace with your .mp3 file path\n",
    "y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "# Define parameters\n",
    "frame_length = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# Initialize a list to store formants for each vowel\n",
    "formants_dict = {}\n",
    "vowel_labels = ['a', 'e', 'i', 'o', 'u'] \n",
    "\n",
    "# Assume the vowels are spaced out in the audio; you can specify the intervals\n",
    "vowel_intervals = [(0.7, 1.5), (2, 2.8), (3.5, 4.1), (5, 5.4), (6.4, 7)]  # Adjust the intervals as necessary\n",
    "\n",
    "# Extract formants for each vowel\n",
    "for i, (start, end) in enumerate(vowel_intervals):\n",
    "    # Select the segment corresponding to the vowel\n",
    "    segment = y[int(start * sr):int(end * sr)]\n",
    "    formants = []\n",
    "    \n",
    "    # Extract formants from the vowel segment\n",
    "    for j in range(0, len(segment), hop_length):\n",
    "        if j + frame_length <= len(segment):\n",
    "            frame = segment[j:j + frame_length]\n",
    "            spectrum = np.abs(np.fft.rfft(frame))\n",
    "            freqs = np.fft.rfftfreq(len(frame), 1/sr)\n",
    "            peaks = np.argsort(spectrum)[-3:]  # Get indices of top 3 frequencies\n",
    "            formants.append([j / sr * 1000, freqs[peaks[0]], freqs[peaks[1]], freqs[peaks[2]]])\n",
    "    \n",
    "    # Store formants in the dictionary\n",
    "    formants_dict[vowel_labels[i]] = pd.DataFrame(formants, columns=['Time (ms)', 'F1', 'F2', 'F3'])\n",
    "\n",
    "# Create subplots for each vowel\n",
    "fig, axs = plt.subplots(5, 1, figsize=(12, 20), sharex=True)\n",
    "\n",
    "# Plotting each vowel's formants\n",
    "for i, vowel in enumerate(vowel_labels):\n",
    "    axs[i].plot(formants_dict[vowel]['Time (ms)'], formants_dict[vowel]['F1'], label='F1', color='blue', linewidth=2)\n",
    "    axs[i].plot(formants_dict[vowel]['Time (ms)'], formants_dict[vowel]['F2'], label='F2', linestyle='--', color='green')\n",
    "    axs[i].plot(formants_dict[vowel]['Time (ms)'], formants_dict[vowel]['F3'], label='F3', linestyle=':', color='red')\n",
    "    axs[i].set_title(f'Formants for Vowel {vowel}')\n",
    "    axs[i].set_ylabel('Frequency (Hz)')\n",
    "    axs[i].set_xlabel('Time (ms)')  # Set x-label for each subplot\n",
    "    axs[i].grid(True)\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "30eddce415c0e9ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Automatic Classification of Vowel Sounds Based on Formant Frequencies\n",
    "\n",
    "##### **Step 1. Load the Speech Signal**\n",
    "Load the .mp3 file containing multiple vowels using librosa.load(). This function reads the audio file and returns two outputs: the audio time series (as a NumPy array) and the sample rate. <br>\n",
    "***Tip:*** To open a WAV file you need to access its directory correctly: `speech_samples/FILE_NAME.wav`\n",
    "\n",
    "##### **Step 2. Define Frame Parameters**\n",
    "Define the parameters for processing the audio signal, including the `frame_length` (2048 samples) and `hop_length` (512 samples). These parameters dictate how the audio is segmented for analysis.\n",
    "\n",
    "##### **Step 3. Initialize Storage for Formants**\n",
    "\n",
    "##### **Step 4. Specify Vowel Intervals & Storage for Formants**\n",
    "Specify the time intervals for each vowel within the audio file. These intervals define the sections of the audio that correspond to the individual vowels, given in seconds.\n",
    "Create a dictionary to store the extracted formants for each vowel. Also, define a list of vowel labels `('a', 'e', 'i', 'o', 'u')` that will be used to identify the formants.\n",
    "\n",
    "##### **Step 5.  Extract Formants and Classify Vowels*\n",
    "For each vowel interval:\n",
    "1. Extract the corresponding audio segment.\n",
    "2. Analyze it in overlapping frames to calculate the formant frequencies.\n",
    "3. Store the average formant frequencies for classification.\n",
    "4. Use the average formants to classify each vowel based on the provided reference formant frequencies for the vowels.\n",
    "\n",
    "##### **Step 6. Classify the Vowels**\n",
    "For each vowel, compare its extracted average formants to the reference formants. Calculate the distance (e.g., Euclidean distance) from each vowel to each reference vowel, and classify it based on the closest match.\n",
    "\n",
    "##### **Step 6. Display Results**\n",
    "Display the classified vowels and their corresponding average formant frequencies.\n",
    "\n",
    "\n",
    "NB! This model is NOT precise!!!"
   ],
   "id": "d36e3e112425d3a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the .mp3 file containing multiple vowels\n",
    "file_path = 'speech_samples/vowels.mp3'  # Replace with your .mp3 file path\n",
    "y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "# Define parameters\n",
    "frame_length = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# Define vowel intervals and labels\n",
    "vowel_intervals = [(0.7, 1.5), (2, 2.8), (3.5, 4.1), (5, 5.4), (6.4, 7)]\n",
    "vowel_labels = ['a', 'e', 'i', 'o', 'u'] \n",
    "\n",
    "# Example reference formant frequencies (F1, F2) for classification\n",
    "# Updated reference formant frequencies (F1, F2) for classification\n",
    "reference_formants = {\n",
    "    'a': [180, 900],\n",
    "    'e': [195, 205],\n",
    "    'i': [134, 270],\n",
    "    'o': [242, 320],\n",
    "    'u': [133, 175],\n",
    "}\n",
    "\n",
    "# Initialize storage for extracted formants\n",
    "extracted_formants = {}\n",
    "\n",
    "# Extract formants and classify\n",
    "for i, (start, end) in enumerate(vowel_intervals):\n",
    "    segment = y[int(start * sr):int(end * sr)]\n",
    "    formants = []\n",
    "    \n",
    "    # Extract formants from the vowel segment\n",
    "    for j in range(0, len(segment), hop_length):\n",
    "        if j + frame_length <= len(segment):\n",
    "            frame = segment[j:j + frame_length]\n",
    "            spectrum = np.abs(np.fft.rfft(frame))\n",
    "            freqs = np.fft.rfftfreq(len(frame), 1/sr)\n",
    "            peaks = np.argsort(spectrum)[-3:]  # Get indices of top 3 frequencies\n",
    "            formants.append([freqs[peaks[0]], freqs[peaks[1]], freqs[peaks[2]]])  # Store F1, F2, F3\n",
    "    \n",
    "    # Calculate average F1 and F2\n",
    "    avg_formants = np.mean(formants, axis=0)[:2]  # Average F1 and F2\n",
    "    extracted_formants[vowel_labels[i]] = avg_formants\n",
    "\n",
    "# Classification based on the closest formant distances\n",
    "classified_vowels = {}\n",
    "\n",
    "for vowel, avg_formant in extracted_formants.items():\n",
    "    distances = {}\n",
    "    for ref_vowel, ref_formants in reference_formants.items():\n",
    "        distance = np.linalg.norm(np.array(avg_formant) - np.array(ref_formants[:2]))  # Distance between F1 and F2\n",
    "        distances[ref_vowel] = distance\n",
    "    \n",
    "    classified_vowels[vowel] = min(distances, key=distances.get)  # Get the vowel with the smallest distance\n",
    "\n",
    "# Print out classified results\n",
    "for vowel, classification in classified_vowels.items():\n",
    "    print(f'Vowel {vowel} classified as {classification} with average formants: {extracted_formants[vowel]} Hz')\n"
   ],
   "id": "5c71a0a1f675ecc9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
